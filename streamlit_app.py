import os
import streamlit as st
import pandas as pd
import matplotlib.pyplot as plt
import matplotlib.font_manager as fm
from sentence_transformers import SentenceTransformer, util
from pytrends.request import TrendReq
import datetime
import requests
import json

# ===== í°íŠ¸ ì„¤ì • =====
def set_korean_font():
    font_path = os.path.join(os.getcwd(), "NanumGothic-Regular.ttf")  # í”„ë¡œì íŠ¸ í´ë” ë‚´ í°íŠ¸ íŒŒì¼
    if os.path.exists(font_path):
        # Matplotlib í°íŠ¸ ë“±ë¡
        fm.fontManager.addfont(font_path)
        plt.rc("font", family="NanumGothic")

        # âœ… ë§ˆì´ë„ˆìŠ¤ ê¸°í˜¸ ê¹¨ì§ ë°©ì§€ ì„¤ì •
        plt.rcParams['axes.unicode_minus'] = False

        # Streamlit HTML ë§ˆí¬ë‹¤ìš´ìœ¼ë¡œ í•œê¸€ í°íŠ¸ ì ìš©
        st.markdown(
            f"""
            <style>
            @font-face {{
                font-family: 'NanumGothic';
                src: url('file://{font_path}') format('truetype');
            }}
            html, body, [class*="css"] {{
                font-family: 'NanumGothic';
            }}
            </style>
            """,
            unsafe_allow_html=True
        )
    else:
        st.warning("â— NanumGothic-Regular.ttf íŒŒì¼ì´ í”„ë¡œì íŠ¸ ê²½ë¡œì— ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")

# ===== ë°ì´í„° ë¡œë”© ë° ì „ì²˜ë¦¬ =====
@st.cache_data
def load_and_preprocess_data(uploaded_file, code_name_file):
    import os
    filename = uploaded_file.name
    _, ext = os.path.splitext(filename)

    # ë§¤ë§¤ê¸°ë¡ ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸°
    if ext == ".csv":
        df = pd.read_csv(uploaded_file, encoding="utf-8")
    elif ext == ".xlsx":
        df = pd.read_excel(uploaded_file, engine="openpyxl")
    else:
        raise ValueError("CSV ë˜ëŠ” XLSX í˜•ì‹ë§Œ ì§€ì›ë©ë‹ˆë‹¤.")

    # ë‚ ì§œ ì „ì²˜ë¦¬
    df["ë§¤ìˆ˜ì¼"] = pd.to_datetime(df["ë§¤ìˆ˜ì¼"])
    df["ë§¤ë„ì¼"] = pd.to_datetime(df["ë§¤ë„ì¼"])
    df["ë³´ìœ ì¼ìˆ˜"] = (df["ë§¤ë„ì¼"] - df["ë§¤ìˆ˜ì¼"]).dt.days

    # âœ… ì¢…ëª©ì½”ë“œ â†’ ì¢…ëª©ëª… ë§¤í•‘
    _, ext2 = os.path.splitext(code_name_file.name)
    if ext2 == ".csv":
        code_df = pd.read_csv(code_name_file, dtype={"ì¢…ëª©ì½”ë“œ": str})
    elif ext2 == ".xlsx":
        code_df = pd.read_excel(code_name_file, dtype={"ì¢…ëª©ì½”ë“œ": str})
    else:
        raise ValueError("ì¢…ëª©ì½”ë“œ ë§¤í•‘ íŒŒì¼ì€ CSV ë˜ëŠ” XLSXë§Œ ì§€ì›ë©ë‹ˆë‹¤.")

    df["ì¢…ëª©ì½”ë“œ"] = df["ì¢…ëª©ì½”ë“œ"].astype(str)
    code_df["ì¢…ëª©ì½”ë“œ"] = code_df["ì¢…ëª©ì½”ë“œ"].astype(str)

    df = df.merge(code_df, on="ì¢…ëª©ì½”ë“œ", how="left")

    # âœ… ë¬¸ì¥ ìƒì„±ìš© ì»¬ëŸ¼ ì¶”ê°€ (ì¢…ëª©ëª… í¬í•¨)
    df["ë¬¸ì¥"] = df.apply(
        lambda row: f"{row['ì¢…ëª©ëª…']}ì˜ RSIëŠ” {row['RSI']}ì´ë©°, ìˆ˜ìµë¥ ì€ {row['ìˆ˜ìµë¥ ']}%ì…ë‹ˆë‹¤.",
        axis=1,
    )

    return df
    
# ===== Top5 ì¢…ëª© ì‹œê°í™” =====
import streamlit as st
import matplotlib.pyplot as plt

def visualize_top5_bar(df, start_date, end_date):
    df["ë§¤ìˆ˜ì¼"] = pd.to_datetime(df["ë§¤ìˆ˜ì¼"], errors='coerce')
    sub_df = df[(df["ë§¤ìˆ˜ì¼"] >= start_date) & (df["ë§¤ìˆ˜ì¼"] <= end_date)]

    top5 = sub_df["ì¢…ëª©ëª…"].value_counts().nlargest(5)

    st.subheader("ğŸ“ˆ ë¶„ì„ê¸°ê°„ Top 5 ë§¤ë§¤ ì¢…ëª©")
    fig, ax = plt.subplots()
    top5.plot(kind="bar", ax=ax)

    ax.set_title("Top 5 ì¢…ëª©ë³„ ë§¤ë§¤ íšŸìˆ˜")
    ax.set_xlabel("ì¢…ëª©ëª…")
    ax.set_ylabel("ë§¤ë§¤ íšŸìˆ˜")
    ax.tick_params(axis='x', labelrotation=45)

    st.pyplot(fig)
    return top5.index.tolist()

# ===== Clova ìš”ì•½ =====
import requests

def clova_analysis(prompt: str) -> str:
    api_key = "nv-b21936503dc049a488669d28299ad294s0i2"
    invoke_url = "https://clovastudio.stream.ntruss.com/v3/chat-completions/HCX-005"

    headers = {
        "Authorization": f"Bearer {api_key}",
        "Content-Type": "application/json"
    }

    payload = {
        "messages": [
            {"role": "system", "content": "ë‹¹ì‹ ì€ íˆ¬ì ë¶„ì„ ì „ë¬¸ê°€ì…ë‹ˆë‹¤."},
            {"role": "user", "content": prompt}
        ],
        "maxTokens": 800,
        "temperature": 0.7,
        "topP": 0.9
    }

    try:
        res = requests.post(invoke_url, headers=headers, json=payload)
        if res.status_code == 200:
            return res.json()['result']['message']['content']
        else:
            return f"âŒ Clova ì˜¤ë¥˜: {res.status_code} - {res.text}"
    except Exception as e:
        return f"âŒ Clova ì˜ˆì™¸ ë°œìƒ: {str(e)}"
        
# ===== Pytrends í‚¤ì›Œë“œ ê²€ìƒ‰ =====
def plot_keyword_trend(keyword):
    pytrends = TrendReq(hl="ko", tz=540)
    today = datetime.date.today()
    past_date = today - datetime.timedelta(days=90)
    pytrends.build_payload([keyword], cat=0, timeframe=f"{past_date} {today}", geo="KR")
    df = pytrends.interest_over_time()
    if not df.empty:
        st.subheader("ğŸ” í‚¤ì›Œë“œ ê²€ìƒ‰ëŸ‰ ì¶”ì´")
        st.line_chart(df[keyword])
    else:
        st.warning("ê²€ìƒ‰ ë°ì´í„°ê°€ ì¶©ë¶„í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")

# ===== RAG ê¸°ë°˜ ìœ ì‚¬ ë¬¸ì¥ ê²€ìƒ‰ =====
def search_similar_sentences(query, corpus, top_k=3):
    model = SentenceTransformer("snunlp/KR-SBERT-V40K-klueNLI-augSTS")
    query_embedding = model.encode(query, convert_to_tensor=True)
    corpus_embeddings = model.encode(corpus, convert_to_tensor=True)
    hits = util.semantic_search(query_embedding, corpus_embeddings, top_k=top_k)[0]
    return [corpus[hit["corpus_id"]] for hit in hits]

set_korean_font()

# ===== main í•¨ìˆ˜ =====
def main():
    st.title("ğŸ“Š íˆ¬ì ë³µê¸° ë¶„ì„ ì‹œìŠ¤í…œ")

    uploaded_file = st.file_uploader("ğŸ“ ë§¤ë§¤ê¸°ë¡ CSV/XLSX íŒŒì¼", type=["csv", "xlsx"])
    code_name_file = st.file_uploader("ğŸ“„ ì¢…ëª©ì½”ë“œ-ì´ë¦„ ë§¤í•‘ íŒŒì¼", type=["csv", "xlsx"])

    if uploaded_file and code_name_file:
        df = load_and_preprocess_data(uploaded_file, code_name_file)

        # "ë§¤ìˆ˜ì¼" ê¸°ì¤€ ë‚ ì§œ ë²”ìœ„
        start_date = st.date_input("ë¶„ì„ ì‹œì‘ì¼", df["ë§¤ìˆ˜ì¼"].min().date())
        end_date = st.date_input("ë¶„ì„ ì¢…ë£Œì¼", df["ë§¤ìˆ˜ì¼"].max().date())

        keyword = st.text_input("ğŸ“Œ ë¶„ì„ í‚¤ì›Œë“œ ì…ë ¥")
        top5 = visualize_top5_bar(df, pd.to_datetime(start_date), pd.to_datetime(end_date))


        # ë¬¸ì¥ ìƒì„± (Clova ìš”ì•½ê³¼ RAG ê²€ìƒ‰ìš©)
        df["ë¬¸ì¥"] = df.apply(
            lambda row: f"{row['ë§¤ìˆ˜ì¼'].strftime('%Y-%m-%d')}ì— {row['ì¢…ëª©ëª…']} ì¢…ëª©ì„ ë§¤ìˆ˜í•˜ì—¬ "
                        f"{row['ë§¤ë„ì¼'].strftime('%Y-%m-%d')}ì— ë§¤ë„, ìˆ˜ìµë¥  {row['ìˆ˜ìµë¥ ']}%, "
                        f"RSI {row['RSI']}, MA5: {row['MA5']}, ë³´ìœ ì¼ìˆ˜: {row['ë³´ìœ ì¼ìˆ˜']}ì¼",
            axis=1
        )

        # âœ… RAG ê¸°ë°˜ ìœ ì‚¬ ë¬¸ì¥ ê²€ìƒ‰
        st.subheader("ğŸ—ƒ RAG ê¸°ë°˜ ìœ ì‚¬ ë¬¸ì¥ ê²€ìƒ‰")
        user_query = st.text_input("ğŸ” ê²€ìƒ‰í•  ë¬¸ì¥ì„ ì…ë ¥í•˜ì„¸ìš”")
        if user_query:
            corpus = df["ë¬¸ì¥"].tolist()
            results = search_similar_sentences(user_query, corpus)
            for idx, r in enumerate(results):
                st.write(f"{idx+1}. {r}")

        # âœ… í‚¤ì›Œë“œ íŠ¸ë Œë“œ ì‹œê°í™”
        if keyword:
            plot_keyword_trend(keyword)

        # âœ… Clova ìš”ì•½ ë¶„ì„
        st.subheader("ğŸ§  Clova ìš”ì•½ ë¶„ì„")
        if st.button("Clovaë¡œ ë¶„ì„ ì‹œì‘"):
            # í†µê³„ ìš”ì•½
            rsi_overheated = df[df["RSI"] >= 70].shape[0]
            short_term = df[df["ë³´ìœ ì¼ìˆ˜"] <= 3].shape[0]
            loss_cut = df[(df["ìˆ˜ìµë¥ "] <= -3) & (df["ë³´ìœ ì¼ìˆ˜"] <= 5)].shape[0]
            summary = (
                f"ğŸ“Œ **ìš”ì•½ í†µê³„**\n"
                f"- RSI 70 ì´ìƒ ë§¤ìˆ˜: **{rsi_overheated}íšŒ**\n"
                f"- 3ì¼ ì´í•˜ ë‹¨ê¸° ë§¤ë§¤: **{short_term}íšŒ**\n"
                f"- -3% ì´ìƒ ì†ì‹¤ + 5ì¼ ì´í•˜ ë³´ìœ  ë§¤ë„: **{loss_cut}íšŒ**\n\n"
            )

            combined_text = "\n".join(df["ë¬¸ì¥"].tolist())

            prompt = (
                f"{summary}"
                f"ğŸ“Œ ì•„ë˜ ë§¤ë§¤ê¸°ë¡ì— ë‚˜ì˜¤ëŠ” ì¢…ëª©ë“¤ì— ëŒ€í•´ ë¶„ì„í•´ì£¼ì„¸ìš”:\n\n"
                f"{combined_text}\n\n"
                f"ğŸ§  ì´ ê¸°ë¡ë“¤ì„ ë°”íƒ•ìœ¼ë¡œ ë‹¤ìŒì„ ë¶„ì„í•´ì£¼ì„¸ìš”:\n"
                f"1. ë°˜ë³µëœ ì†ì‹¤ ì›ì¸\n"
                f"2. ë³´ì™„í•  ì \n"
                f"3. ìˆ˜ìµ ì „ëµì˜ ê³µí†µì \n"
                f"ê°„ê²°í•˜ê³  ì‹¤ìš©ì ì¸ íˆ¬ì ì¡°ì–¸ì„ ì¤‘ì‹¬ìœ¼ë¡œ ë‹µí•´ì£¼ì„¸ìš”."
            )

            result = clova_analysis(prompt)
            st.markdown("#### âœ… ë¶„ì„ ê²°ê³¼")
            st.markdown(result)

if __name__ == "__main__":
    main()